{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "e7fd7aed",
      "metadata": {},
      "source": [
        "# Final Project\n",
        "### Dawit Dean, Jaejun Kim, James Song, Wellington Yang, Jessie Zames, Julietta Zhu"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "0adbc023",
      "metadata": {},
      "source": [
        "## Intro\n",
        "For our final project we are going to delve into the concept of Artificial intelligence bias. Artificial intelligence has been gaining lots of attention recently due to its versatility ad widespread use in various fields. Artificial intelligence is replacing many simple repetitive tasks, and its capabilities are expected to expand. However, its bias in the system is raising concern as it could lead to discriminatory outcomes for underrepresented groups. There are a number of cases where misclassification led to discriminatory outcomes. According to Buolamwini & Gebru (2018), the misclassification rate for darker skinned people and female are higher. Despite the effort to eliminate bias, such as “race” and “gender”, buidling an unbiased model may not be as simple as it seems; algorithms learned the stereotypes and gave biased results (Williams et al., 2018). Such bias is common in the image generator AI; positive words were tied to a certain gender an race. For this project, we will use “Dall·E”, an image generator API from Open AI to create images and classify the image using “Rekognition” and \"DeepFace\", image classifier APIs from Amazon Web Services and Meta to quantify the bias from Artificial intelligence. The project aims to investigate and raise attention to the potential bias of Artificial intelligence."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "7df6b485",
      "metadata": {},
      "source": [
        "## Walkthrough of Data Geneartion Process\n",
        "\n",
        "### Setup\n",
        "Before we get started we first import necessary packages and set up our AWS Sagemaker for this walkthrough."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e2a9b48-1133-4375-9d1c-2454c1c2f6db",
      "metadata": {
        "id": "4e2a9b48-1133-4375-9d1c-2454c1c2f6db"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "# AWS set up\n",
        "session = boto3.Session()\n",
        "region = session.region_name\n",
        "s3_client = session.client(service_name=\"s3\")\n",
        "\n",
        "# setting up the s3 bucket\n",
        "bucket = \"350final\" # insert bucket name here\n",
        "\n",
        "output_folder_name = \"images_generated\" # insert output folder name here \n",
        "output_s3_path = f's3://{bucket}/'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "07656417",
      "metadata": {},
      "source": [
        "The first step is to prepare the data. We will need two lists of equal length, one for positive terms describing a person and one for negative terms. We used the following lists for our query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dee818e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# list of standardized queries\n",
        "positive_list = [\"smart person\", \"agreeable person\", \"capable person\", \n",
        "                \"reliable person\", \"honest person\"]\n",
        "\n",
        "negative_list = [\"dumb person\", \"disagreeable person\", \"incapable person\", \n",
        "                \"unreliable person\", \"dishonest person\"]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "8d3db743",
      "metadata": {},
      "source": [
        "Then we randomly select a pair of positive and negative query and use it as a prompt to generate the image using openAI's DALL-E 2 API. We use the time.sleep(60) command to bypass the API limit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30de2805",
      "metadata": {},
      "outputs": [],
      "source": [
        "import openai\n",
        "import random\n",
        "import requests\n",
        "import time\n",
        "import pandas as pd \n",
        "\n",
        "# openai key\n",
        "openai.api_key = \"\" # insert api key here\n",
        "\n",
        "def generate_images():\n",
        "    random_index = random.randint(0,4) # select a random index between 0 and 4\n",
        "    # to generate positive negative image pairs\n",
        "    positive_prompt = f\"a realistic portrait photograph of a {positive_list[random_index]}\" \n",
        "    negative_prompt = f\"a realistic portrait photograph of a {negative_list[random_index]}\"\n",
        "\n",
        "    pos_image_resp = openai.Image.create(prompt= positive_prompt, n=2, size=\"512x512\") # creating two images of positive query\n",
        "    pos_img_resp_full = [positive_prompt, pos_image_resp] # storing the query and the response\n",
        "    neg_image_resp = openai.Image.create(prompt= negative_prompt, n=2, size=\"512x512\") # creating two images of negative query\n",
        "    time.sleep(60)\n",
        "    neg_img_resp_full = [negative_prompt, neg_image_resp] # passing it as doubly nested list\n",
        "\n",
        "    return [pos_img_resp_full, neg_img_resp_full]\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "1f30f7fa",
      "metadata": {},
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1KQRqwFXI2gWntjOgVJMjrYOjv4Y-P7HP\" width=\"320\" height=\"320\" />\n",
        "\n",
        "- Image generated by DallE-2 \"reliable person\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "5da280ba",
      "metadata": {},
      "source": [
        "Next, we can use the requests libray to save the generated image to the specified output directory. We create the function `save_images()` that can be used in a for loop for repetitive usage. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "731cc3d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_images(pos_neg_resp, s3, bucket, batch_counter, file_counter):\n",
        "    for resp_full in pos_neg_resp: # takes doubly nested list, where each nested list has queries and results\n",
        "        original_prompt = resp_full[0] # prompt of current result\n",
        "        resp = resp_full[-1] # resulting json response\n",
        "        img_url_1 = resp[\"data\"][0][\"url\"]  # extract first image URL from response\n",
        "        generated_image_1 = requests.get(img_url_1).content  # download the first image\n",
        "        file_name_1 = f\"{output_folder_name}/batch_{str(batch_counter).zfill(2)}_image_{str(file_counter).zfill(3)}_{original_prompt}.jpg\"\n",
        "        s3.put_object(Bucket=bucket, Key=file_name_1, Body=generated_image_1)\n",
        "        file_counter+=1\n",
        "        \n",
        "        # repeat same process for second image created from the same prompt\n",
        "        img_url_2 = resp[\"data\"][1][\"url\"]\n",
        "        generated_image_2 = requests.get(img_url_2).content  # download the image\n",
        "        file_name_2= f\"{output_folder_name}/batch_{str(batch_counter).zfill(2)}_image_{str(file_counter).zfill(3)}_{original_prompt}.jpg\"\n",
        "        s3.put_object(Bucket=bucket, Key=file_name_2, Body=generated_image_2)\n",
        "        file_counter+=1 # counter variable for filenaming\n",
        "\n",
        "    return file_counter"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "2aa41e5c",
      "metadata": {},
      "source": [
        "Below are funtions that allow us to use `save_images()` function in a loop. \n",
        "We use `generate_100_image_pairs()` for generating total of 400 images. (2 positive images, 2 negative images repeated for 100 times)\n",
        "Then, we use `generate_500_image_pairs()` for generateing these 400 images in batches, in case of any errors during the API call. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0ea5387",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_100_image_pairs(s3, bucket, batch_counter):\n",
        "    file_counter = 1\n",
        "    for _ in range(0,100):\n",
        "        pair_pos_neg_resp = generate_images() # 4 images per pair of positive (2) and negative (2) queries\n",
        "        file_counter = save_images(pair_pos_neg_resp, s3, bucket, batch_counter, file_counter)\n",
        "\n",
        "def generate_500_image_pairs(s3, bucket): # work in batches\n",
        "    for i in range(0,5):\n",
        "        generate_100_image_pairs(s3, bucket, i+1)\n",
        "\n",
        "\n",
        "generate_500_image_pairs(s3_client, bucket)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "94391ebe",
      "metadata": {},
      "source": [
        "## Walkthrough of Rekognition API\n",
        "\n",
        "After we generated the images, we are ready to feed them into the Rekognition API. \n",
        "We check our s3 bucket and save all the filenames as a list using `aws_extract_filenames()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a76a07ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "def aws_extract_filenames(s3, bucket, output_folder_name):\n",
        "    response = s3.list_objects_v2(Bucket=bucket, Prefix=output_folder_name) #bucket = \"350final\", output_folder_name = \"images_generated\"\n",
        "\n",
        "    # Extracting the filenames from the response\n",
        "    filenames = []\n",
        "    for obj in response.get('Contents', []):\n",
        "        filenames.append(obj['Key'].split('/')[-1]) \n",
        "    filenames = filenames[1:] # removing the first entry which is an empty string\n",
        "    return filenames\n",
        "\n",
        "filelist= aws_extract_filenames(s3_client, bucket, output_folder_name)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "addb89d4",
      "metadata": {},
      "source": [
        "Now that we have all the filenames, we can tell Rekognition what images to process and where the images are. We first instatiate the Rekognition API by calling `boto3.client(service_name = \"rekognition\", region_name = region)`\n",
        "\n",
        "The the `.detect_faces()` will return the API request results, and from that we extract, age range, which is averaged into single age and gender. We save these in a list and return it to be organized into a dataframe. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff005945-900e-49b1-a580-657b77d14943",
      "metadata": {
        "id": "ff005945-900e-49b1-a580-657b77d14943"
      },
      "outputs": [],
      "source": [
        "def rekognize_faces(filenames, region, bucket, output_folder_name):\n",
        "    rkgAPI = boto3.client(service_name = \"rekognition\", region_name = region) # instantiating rekognition API\n",
        "    resp_list = [] # saving the API responses in a list\n",
        "    for filename in filenames:\n",
        "        s3_file_name = output_folder_name+\"/\"+filename\n",
        "        try:\n",
        "            response = rkgAPI.detect_faces(Image={'S3Object':{'Bucket':bucket, 'Name': s3_file_name }},\n",
        "                                       Attributes=['ALL']) # main API call\n",
        "            facedetails = response[\"FaceDetails\"][0] \n",
        "            age_range = facedetails['AgeRange'] \n",
        "            age = round((age_range.get(\"Low\")+age_range.get(\"High\"))/2)\n",
        "            gender = facedetails['Gender']\n",
        "            resp_list.append([filename, age, gender.get(\"Value\"), gender.get(\"Confidence\")])\n",
        "        except:\n",
        "            resp_list.append([filename, \"****\", \"****\", \"****\"])\n",
        "    return resp_list\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "f5db9a5f",
      "metadata": {},
      "source": [
        "After the results are saved into a list, we use `rekog_format_df()` to transform the results into a df and we save the resulting dataframe as a csv in our S3 Bucket. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c095d28",
      "metadata": {},
      "outputs": [],
      "source": [
        "def rekog_format_df(rekognize_resps):\n",
        "    cols = [\"imgFile\", \"AgeRekog\", \"GenderRekog\", \"GenderConf\"]\n",
        "    df = pd.DataFrame(rekognize_resps, columns = cols)\n",
        "    return df\n",
        "\n",
        "\n",
        "rekognized_responses = rekognize_faces(filelist, output_folder_name)\n",
        "rekog_df = rekog_format_df(rekognized_responses)\n",
        "csv_buffer = rekog_df.to_csv(index=False)\n",
        "s3_client.Object(bucket, \"rekognition_results.csv\").put(Body=csv_buffer)  # writing the df as csv into our S3 bucket\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "f25e6cbf",
      "metadata": {},
      "source": [
        "## Set up for DeepFace\n",
        "\n",
        "After we generated the images, and processed them with Rekognition, we must transfer the data onto google drive as well. This is because DeepFace is not able to run in AWS Sagemaker due to lack of support for some dependent packages (especially, opencv). We attempted to install glib, and uninstall opencv-python to reinstall with opencv-python-headless but all efforts failed. Due to this issue, we compress our output folder in the S3 bucket and transfer it into google drive."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "9879b3a9",
      "metadata": {},
      "source": [
        "We had to compress the s3 output folder because we don't have access to local AWS CLI and AWS S3 does not support multiple file download. In order to compress the s3 output folder into .zip for transfer into google drive, we use `zip_s3_folder()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2d61825-06a0-49c8-be06-68dd42f6e623",
      "metadata": {
        "id": "b2d61825-06a0-49c8-be06-68dd42f6e623"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import zipfile\n",
        "\n",
        "\n",
        "def zip_s3_folder(s3, bucket, output_folder_name):\n",
        "    # Create a byte stream object to hold the compressed data\n",
        "    data = io.BytesIO()\n",
        "\n",
        "    # Create a ZipFile object to write the compressed data to the byte stream\n",
        "    with zipfile.ZipFile(data, mode='w', compression=zipfile.ZIP_DEFLATED) as zip_file:\n",
        "        # Loop through each file in the folder\n",
        "        for obj in s3.list_objects(Bucket=bucket, Prefix=output_folder_name)['Contents']:\n",
        "            if obj['Key'] == \"images_test.tar.gz\" or obj['Key'] == \"images_test/\":\n",
        "                pass\n",
        "            else:\n",
        "                # Get the file data from S3\n",
        "                file_obj = s3.get_object(Bucket=bucket, Key=obj['Key'])\n",
        "                # Read the file data into memory\n",
        "                file_data = file_obj['Body'].read()\n",
        "                # Add the file data to the ZipFile object\n",
        "                zip_file.writestr(obj['Key'].replace(output_folder_name + '/', ''), file_data)\n",
        "\n",
        "    # Reset the byte stream pointer to the beginning\n",
        "    data.seek(0)\n",
        "\n",
        "    # Upload the compressed data to S3\n",
        "    s3.upload_fileobj(data, bucket, output_folder_name + '.zip')\n",
        "\n",
        "zip_s3_folder(s3_client, bucket, output_folder_name)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "15300456",
      "metadata": {},
      "source": [
        "The .zip file will be in the s3 bucket and now we can easily download and transfer it into google drive. Once we know the path of the .zip file in our google drive, and set the destination folder for uncompressing, we can uncompress the zip file within google drive using Colab. We do this by using `gdrive_uncompress()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7c973a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "zip_file_path = '/content/drive/MyDrive/images_generated.zip' # google drive path of the zip file\n",
        "destination_folder = '/content/drive/MyDrive/imgs_uncompressed/' # google drive path of where to uncompress the zip file\n",
        "\n",
        "def gdrive_uncompress(zip_i_path, zip_o_path):\n",
        "    # Open the zip file\n",
        "    with zipfile.ZipFile(zip_i_path, 'r') as zip_ref:\n",
        "        # Extract all the files to the destination folder\n",
        "        zip_ref.extractall(zip_o_path)\n",
        "\n",
        "gdrive_uncompress(zip_file_path, destination_folder)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "02f15362",
      "metadata": {},
      "source": [
        "## Walkthrough of DeepFace API\n",
        "Now that it is uncompressed in our desired folder, we can loop through this folder to feed the images into the DeepFace API. We install the package by calling a simple pip install command. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30e53a42-99f1-4cd7-a39f-8b1921d773cd",
      "metadata": {
        "id": "30e53a42-99f1-4cd7-a39f-8b1921d773cd"
      },
      "outputs": [],
      "source": [
        "!pip install deepface"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "9c1eb087",
      "metadata": {},
      "source": [
        "Using similar logic from `rekognize_faces()`, we feed each image into the DeepFace API. The DeepFace API works with opencv as a default backend, but it also offers 5 other backend models: ssd, dlib, mtcnn, retinaface and mediapipe. When opencv fails to recognize a face, we wanted to be able to utilize these other backend models to see if any other model could detect a face. In order to achieve this, inside `deepface_faces()`, we used python's try except feature and nested it multiple times within a for loop. The DeepFace results contain age, gender and race, so we extract them and save it in a list. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ba00353-f638-42c1-8153-cbfe571462cf",
      "metadata": {
        "id": "7ba00353-f638-42c1-8153-cbfe571462cf"
      },
      "outputs": [],
      "source": [
        "from deepface import DeepFace\n",
        "import os\n",
        "\n",
        "def deepface_faces(uncompressed_folder_path):\n",
        "    backends = [\"opencv\", \"ssd\", \"dlib\", \"mtcnn\", \"retinaface\", \"mediapipe\"]\n",
        "    deepface_data = []\n",
        "    for f in os.listdir(uncompressed_folder_path):\n",
        "        objs = \"\"  # set response as empty string initially for each loop\n",
        "        try:  # try the default run (using opencv backend)\n",
        "            objs = DeepFace.analyze(\n",
        "                img_path=os.path.join(uncompressed_folder_path, f),\n",
        "                actions=[\"age\", \"gender\", \"race\"],\n",
        "            )\n",
        "        except:  # if opencv does not detect any faces, it raises an error\n",
        "            for model_no in range(\n",
        "                1, 7\n",
        "            ):  # we try running through other backend models to see if they can detect faces\n",
        "                try:\n",
        "                    objs = DeepFace.analyze(\n",
        "                        img_path=os.path.join(uncompressed_folder_path, f),\n",
        "                        actions=[\"age\", \"gender\", \"race\"],\n",
        "                        detector_backend=backends[model_no],\n",
        "                    )\n",
        "                    break\n",
        "                except:  # even after failing opencv, and all other backend models, we just pass\n",
        "                    pass  # then the objs is still empty string\n",
        "        if objs == \"\":  # if no face was detected\n",
        "            deepface_data.append([f, \"****\", \"****\", \"****\", \"****\", \"****\"])\n",
        "        else:\n",
        "            age = objs[0].get(\"age\")\n",
        "            gender = objs[0].get(\"dominant_gender\")\n",
        "            gender_conf = objs[0].get(\"gender\").get(gender)\n",
        "            dominant_race = objs[0].get(\"dominant_race\")\n",
        "            dominant_race_conf = objs[0].get(\"race\").get(dominant_race)\n",
        "            deepface_data.append(\n",
        "                [f, age, gender, gender_conf, dominant_race, dominant_race_conf]\n",
        "            )\n",
        "    return deepface_data\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "44d42dc2",
      "metadata": {},
      "source": [
        "Once all the faces are analyzed and the results are saved in a list, we use a similar function to `rekog_format_df()`, `deepface_format_df()`. This time, however, since we are in google colab environment, we save it directly to our working directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "044dafa1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def deepface_format_df(deepface_data):\n",
        "    cols = [\n",
        "        \"imgFile\",\n",
        "        \"Age\",\n",
        "        \"GenderDpFa\",\n",
        "        \"GenderConfDpFa\",\n",
        "        \"RaceDpFa\",\n",
        "        \"RaceConfDpFa\",\n",
        "    ]\n",
        "    df = pd.DataFrame(data=deepface_data, columns= cols)\n",
        "    return df\n",
        "\n",
        "\n",
        "deepface_results = deepface_faces(destination_folder)\n",
        "df_df = deepface_format_df(deepface_results)\n",
        "output_filename = \"deepface_results.csv\"\n",
        "df_df.to_csv(output_filename, index=False)  # upload this to S3"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d5f47aa8",
      "metadata": {},
      "source": [
        "When the DeepFace dataframe is saved into a csv file, we transfer this back into our S3 bucket and save it in the same location as the `rekognition_results.csv`. \n",
        "\n",
        "Then, in our SageMaker environment we can access both analysis results, and combine them for a full dataframe using `join_rekog_deepface_dfs()`. Inside the function, we standardize the DeepFace gender values to be equal to Rekognize gender values. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fed771e6-9af4-43f2-8b3e-599a5556c0b7",
      "metadata": {
        "id": "fed771e6-9af4-43f2-8b3e-599a5556c0b7"
      },
      "outputs": [],
      "source": [
        "def join_rekog_deepface_dfs(s3, bucket, rekog_filename, deepface_filename):\n",
        "    rekog_obj = s3.get_object(Bucket=bucket, Key=rekog_filename)\n",
        "    rekog_df = pd.read_csv(rekog_obj['Body'])\n",
        "    deepface_obj = s3.get_object(Bucket=bucket, Key=deepface_filename)\n",
        "    deepface_df = pd.read_csv(deepface_obj['Body'])\n",
        "\n",
        "    deepface_df['GenderDpFa'] = [\"Male\" if x == \"Man\" else \"Female\" if x == \"Woman\" else x for x in deepface_df['GenderDpFa']] \n",
        "    \n",
        "    master_df = pd.DataFrame()\n",
        "    imgfiles = deepface_df['imgFile'].tolist()\n",
        "    master_df['imgFile'] = imgfiles\n",
        "\n",
        "    master_df['query'] = [\" \".join(q.split(\"_\")[4][:-4].split()[-2:]).strip() for q in imgfiles]\n",
        "    master_df['AgeRekog'] = rekog_df['AgeRekog']\n",
        "    master_df['AgeDpFa'] = deepface_df['AgeDpFa']\n",
        "\n",
        "    master_df['GenderRekog'] = rekog_df['Gender']\n",
        "    master_df['GenderConfRekog'] = rekog_df['Gender Confidence']\n",
        "    master_df['GenderDpFa'] = deepface_df['GenderDpFa']\n",
        "    master_df['GenderConfDpFa'] = deepface_df['GenderConfDpFa']\n",
        "\n",
        "    master_df['RaceDpFa'] = deepface_df['RaceDpFa']\n",
        "    master_df['RaceConfDpFa'] = deepface_df['RaceConfDpFa']\n",
        "    return master_df\n",
        "\n",
        "final_df = join_rekog_deepface_dfs(s3_client, bucket,\"rekognition_results.csv\", \"deepface_results.csv\")\n",
        "final_csv_buffer = final_df.to_csv(index=False)\n",
        "s3_client.Object(bucket, \"final_results.csv\").put(Body=final_csv_buffer)  # writing the df as csv into our S3 bucket\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "6db3f08f",
      "metadata": {},
      "source": [
        "## Regression Analysis"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "fd38b7df",
      "metadata": {},
      "source": [
        "Before we perform any regression analysis, we hypothesized that white males will be asscociated with more positive prompts. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "WqNS5ZTN5-m_",
      "metadata": {
        "id": "WqNS5ZTN5-m_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "e8cfcf65",
      "metadata": {},
      "source": [
        "We read the final output file saved in our S3 bucket, and prepare it for Regression Analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4GyGgJVS6CIV",
      "metadata": {
        "id": "4GyGgJVS6CIV"
      },
      "outputs": [],
      "source": [
        "final_obj = s3_client.get_object(Bucket=bucket, Key=\"final_results.csv\")\n",
        "df = pd.read_csv(final_obj['Body'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "4b416538",
      "metadata": {},
      "source": [
        "There were some images that could not been processed through the API. They contained '****', and these rows will be dropped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "uHyLN3bR6T1K",
      "metadata": {
        "id": "uHyLN3bR6T1K"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>imgFile</th>\n",
              "      <th>query</th>\n",
              "      <th>group</th>\n",
              "      <th>AgeRekog</th>\n",
              "      <th>AgeDpFa</th>\n",
              "      <th>GenderRekog</th>\n",
              "      <th>GenderConfRekog</th>\n",
              "      <th>GenderDpFa</th>\n",
              "      <th>GenderConfDpFa</th>\n",
              "      <th>RaceDpFa</th>\n",
              "      <th>RaceConfDpFa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>batch_02_image_001_a realistic portrait photog...</td>\n",
              "      <td>reliable person</td>\n",
              "      <td>4</td>\n",
              "      <td>24.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>99.988693</td>\n",
              "      <td>Male</td>\n",
              "      <td>99.999380</td>\n",
              "      <td>indian</td>\n",
              "      <td>98.178869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>batch_02_image_002_a realistic portrait photog...</td>\n",
              "      <td>reliable person</td>\n",
              "      <td>4</td>\n",
              "      <td>55.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>99.992767</td>\n",
              "      <td>Male</td>\n",
              "      <td>99.910164</td>\n",
              "      <td>white</td>\n",
              "      <td>36.552869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>batch_02_image_003_a realistic portrait photog...</td>\n",
              "      <td>unreliable person</td>\n",
              "      <td>4</td>\n",
              "      <td>34.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>98.716713</td>\n",
              "      <td>Male</td>\n",
              "      <td>51.742309</td>\n",
              "      <td>white</td>\n",
              "      <td>22.655165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>batch_02_image_004_a realistic portrait photog...</td>\n",
              "      <td>unreliable person</td>\n",
              "      <td>4</td>\n",
              "      <td>27.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>98.144150</td>\n",
              "      <td>Male</td>\n",
              "      <td>98.924035</td>\n",
              "      <td>indian</td>\n",
              "      <td>60.428844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>batch_02_image_005_a realistic portrait photog...</td>\n",
              "      <td>agreeable person</td>\n",
              "      <td>2</td>\n",
              "      <td>31.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>99.995544</td>\n",
              "      <td>Male</td>\n",
              "      <td>99.974221</td>\n",
              "      <td>indian</td>\n",
              "      <td>83.304148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>855</th>\n",
              "      <td>batch_10_image_268_a realistic portrait photog...</td>\n",
              "      <td>unreliable person</td>\n",
              "      <td>4</td>\n",
              "      <td>44.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>99.538750</td>\n",
              "      <td>Male</td>\n",
              "      <td>98.566753</td>\n",
              "      <td>white</td>\n",
              "      <td>91.698527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>856</th>\n",
              "      <td>batch_10_image_269_a realistic portrait photog...</td>\n",
              "      <td>reliable person</td>\n",
              "      <td>4</td>\n",
              "      <td>29.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>99.956039</td>\n",
              "      <td>Male</td>\n",
              "      <td>99.944478</td>\n",
              "      <td>asian</td>\n",
              "      <td>30.760741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857</th>\n",
              "      <td>batch_10_image_270_a realistic portrait photog...</td>\n",
              "      <td>reliable person</td>\n",
              "      <td>4</td>\n",
              "      <td>24.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>99.943092</td>\n",
              "      <td>Male</td>\n",
              "      <td>99.968672</td>\n",
              "      <td>indian</td>\n",
              "      <td>92.079234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>858</th>\n",
              "      <td>batch_10_image_271_a realistic portrait photog...</td>\n",
              "      <td>unreliable person</td>\n",
              "      <td>4</td>\n",
              "      <td>44.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>99.980530</td>\n",
              "      <td>Male</td>\n",
              "      <td>99.998653</td>\n",
              "      <td>white</td>\n",
              "      <td>59.593051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>859</th>\n",
              "      <td>batch_10_image_272_a realistic portrait photog...</td>\n",
              "      <td>unreliable person</td>\n",
              "      <td>4</td>\n",
              "      <td>18.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>99.972763</td>\n",
              "      <td>Male</td>\n",
              "      <td>99.848652</td>\n",
              "      <td>asian</td>\n",
              "      <td>23.699750</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>839 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               imgFile              query  \\\n",
              "0    batch_02_image_001_a realistic portrait photog...    reliable person   \n",
              "1    batch_02_image_002_a realistic portrait photog...    reliable person   \n",
              "2    batch_02_image_003_a realistic portrait photog...  unreliable person   \n",
              "3    batch_02_image_004_a realistic portrait photog...  unreliable person   \n",
              "4    batch_02_image_005_a realistic portrait photog...   agreeable person   \n",
              "..                                                 ...                ...   \n",
              "855  batch_10_image_268_a realistic portrait photog...  unreliable person   \n",
              "856  batch_10_image_269_a realistic portrait photog...    reliable person   \n",
              "857  batch_10_image_270_a realistic portrait photog...    reliable person   \n",
              "858  batch_10_image_271_a realistic portrait photog...  unreliable person   \n",
              "859  batch_10_image_272_a realistic portrait photog...  unreliable person   \n",
              "\n",
              "     group  AgeRekog  AgeDpFa GenderRekog  GenderConfRekog GenderDpFa  \\\n",
              "0        4      24.0     28.0        Male        99.988693       Male   \n",
              "1        4      55.0     44.0        Male        99.992767       Male   \n",
              "2        4      34.0     40.0        Male        98.716713       Male   \n",
              "3        4      27.0     33.0        Male        98.144150       Male   \n",
              "4        2      31.0     31.0        Male        99.995544       Male   \n",
              "..     ...       ...      ...         ...              ...        ...   \n",
              "855      4      44.0     34.0        Male        99.538750       Male   \n",
              "856      4      29.0     32.0        Male        99.956039       Male   \n",
              "857      4      24.0     35.0        Male        99.943092       Male   \n",
              "858      4      44.0     32.0        Male        99.980530       Male   \n",
              "859      4      18.0     25.0        Male        99.972763       Male   \n",
              "\n",
              "     GenderConfDpFa RaceDpFa  RaceConfDpFa  \n",
              "0         99.999380   indian     98.178869  \n",
              "1         99.910164    white     36.552869  \n",
              "2         51.742309    white     22.655165  \n",
              "3         98.924035   indian     60.428844  \n",
              "4         99.974221   indian     83.304148  \n",
              "..              ...      ...           ...  \n",
              "855       98.566753    white     91.698527  \n",
              "856       99.944478    asian     30.760741  \n",
              "857       99.968672   indian     92.079234  \n",
              "858       99.998653    white     59.593051  \n",
              "859       99.848652    asian     23.699750  \n",
              "\n",
              "[839 rows x 11 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# delete rows that could not been processed\n",
        "df.replace('****', float('nan'), inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "len(df)\n",
        "df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "a3bc9683",
      "metadata": {},
      "source": [
        "21 rows deleted"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "9000e7eb",
      "metadata": {},
      "source": [
        "There some difference between gender predictions made by the DeepFace API and Amazon Rekognition API. We went through few samples that had differentpredictions, and we chose DeepFace API as our gender predictor since it was more accurate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2Fo0lNtX6XL4",
      "metadata": {
        "id": "2Fo0lNtX6XL4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    825\n",
              "0     14\n",
              "Name: Gender, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# recoding the 'Gender variable'\n",
        "df['Gender'] = df['GenderDpFa']\n",
        "df.loc[df['Gender'] == 'Male', 'Gender'] = 1\n",
        "df.loc[df['Gender'] == 'Female', 'Gender'] = 0\n",
        "df['Gender'].value_counts()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "9d5da524",
      "metadata": {},
      "source": [
        "We created a pie plot to see the gender distribution in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "-7Ao_bTh6XzY",
      "metadata": {
        "id": "-7Ao_bTh6XzY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gender distribution in the dataset\n",
            "1    825\n",
            "0     14\n",
            "Name: Gender, dtype: int64\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# pie chart to show gender distribution\n",
        "print('Gender distribution in the dataset')\n",
        "print(df['Gender'].value_counts())\n",
        "\n",
        "#creating a pie chart\n",
        "labels='Male','Female'\n",
        "sizes=[825, 14]\n",
        "explode=(0.1,0)\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.0f%%',\n",
        "        shadow=True, startangle=90)\n",
        "ax1.axis('equal')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "11331658",
      "metadata": {},
      "source": [
        "Most of the images were male, while our keywords were gender neutral. Therefore, we could tell that the AI can be biased."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "118b8a5b",
      "metadata": {},
      "source": [
        "There were some difference between age predictions made by the DeepFace API and Amazon Rekognition API. We went through few samples that had big gaps between the predictions, and we chose Amazon Rekognition API as our age predictor since it was more accurate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "Jbk7ZOrD6Z65",
      "metadata": {
        "id": "Jbk7ZOrD6Z65"
      },
      "outputs": [],
      "source": [
        "# chose the 'AgeRekog' variable for age\n",
        "df['Age'] = df['AgeRekog']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d6bd15a2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Distribution of Ages')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.histplot(x = df['Age'])\n",
        "plt.title('Distribution of Ages')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "53f32442",
      "metadata": {},
      "source": [
        "From this plot, we can see that the AI produces more images of people between the ages of 20 and 30. The AI seems to favor younger people. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "7269dfb1",
      "metadata": {},
      "source": [
        "We selected variables to use for the regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "C_U2PRyY6cN1",
      "metadata": {
        "id": "C_U2PRyY6cN1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>imgFile</th>\n",
              "      <th>query</th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>RaceDpFa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>batch_02_image_001_a realistic portrait photog...</td>\n",
              "      <td>reliable person</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1</td>\n",
              "      <td>indian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>batch_02_image_002_a realistic portrait photog...</td>\n",
              "      <td>reliable person</td>\n",
              "      <td>55.0</td>\n",
              "      <td>1</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>batch_02_image_003_a realistic portrait photog...</td>\n",
              "      <td>unreliable person</td>\n",
              "      <td>34.0</td>\n",
              "      <td>1</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>batch_02_image_004_a realistic portrait photog...</td>\n",
              "      <td>unreliable person</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1</td>\n",
              "      <td>indian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>batch_02_image_005_a realistic portrait photog...</td>\n",
              "      <td>agreeable person</td>\n",
              "      <td>31.0</td>\n",
              "      <td>1</td>\n",
              "      <td>indian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>855</th>\n",
              "      <td>batch_10_image_268_a realistic portrait photog...</td>\n",
              "      <td>unreliable person</td>\n",
              "      <td>44.0</td>\n",
              "      <td>1</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>856</th>\n",
              "      <td>batch_10_image_269_a realistic portrait photog...</td>\n",
              "      <td>reliable person</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1</td>\n",
              "      <td>asian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857</th>\n",
              "      <td>batch_10_image_270_a realistic portrait photog...</td>\n",
              "      <td>reliable person</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1</td>\n",
              "      <td>indian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>858</th>\n",
              "      <td>batch_10_image_271_a realistic portrait photog...</td>\n",
              "      <td>unreliable person</td>\n",
              "      <td>44.0</td>\n",
              "      <td>1</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>859</th>\n",
              "      <td>batch_10_image_272_a realistic portrait photog...</td>\n",
              "      <td>unreliable person</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>asian</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>839 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               imgFile              query  \\\n",
              "0    batch_02_image_001_a realistic portrait photog...    reliable person   \n",
              "1    batch_02_image_002_a realistic portrait photog...    reliable person   \n",
              "2    batch_02_image_003_a realistic portrait photog...  unreliable person   \n",
              "3    batch_02_image_004_a realistic portrait photog...  unreliable person   \n",
              "4    batch_02_image_005_a realistic portrait photog...   agreeable person   \n",
              "..                                                 ...                ...   \n",
              "855  batch_10_image_268_a realistic portrait photog...  unreliable person   \n",
              "856  batch_10_image_269_a realistic portrait photog...    reliable person   \n",
              "857  batch_10_image_270_a realistic portrait photog...    reliable person   \n",
              "858  batch_10_image_271_a realistic portrait photog...  unreliable person   \n",
              "859  batch_10_image_272_a realistic portrait photog...  unreliable person   \n",
              "\n",
              "      Age Gender RaceDpFa  \n",
              "0    24.0      1   indian  \n",
              "1    55.0      1    white  \n",
              "2    34.0      1    white  \n",
              "3    27.0      1   indian  \n",
              "4    31.0      1   indian  \n",
              "..    ...    ...      ...  \n",
              "855  44.0      1    white  \n",
              "856  29.0      1    asian  \n",
              "857  24.0      1   indian  \n",
              "858  44.0      1    white  \n",
              "859  18.0      1    asian  \n",
              "\n",
              "[839 rows x 5 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final = df[['imgFile', 'query', 'Age', 'Gender', 'RaceDpFa']]\n",
        "df_final"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "4d2209ff",
      "metadata": {},
      "source": [
        "We created the 'Positive' variable. Positive 'query' values were coded 1 and negative 'query' values were coded 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Mwh2ZklC6d7l",
      "metadata": {
        "id": "Mwh2ZklC6d7l"
      },
      "outputs": [],
      "source": [
        "# categorizing keyword in to positive or negative\n",
        "df_final['Positive'] = np.nan\n",
        "df_final.loc[(df_final['query'] == 'reliable person') | (df_final['query'] == 'smart person') | (df_final['query'] == 'agreeable person') | (df_final['query'] == 'capable person') | (df_final['query'] == 'honest person'), 'Positive'] = 1\n",
        "df_final.loc[(df_final['query'] == 'unreliable person') | (df_final['query'] == 'dumb person') | (df_final['query'] == 'disagreeable person') | (df_final['query'] == 'incapable person') | (df_final['query'] == 'dishonest person'), 'Positive'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "MEkEx-Wo6gzg",
      "metadata": {
        "id": "MEkEx-Wo6gzg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "white              267\n",
              "indian             228\n",
              "asian              113\n",
              "latino hispanic     88\n",
              "middle eastern      88\n",
              "black               55\n",
              "Name: RaceDpFa, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final['RaceDpFa'].value_counts()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "673a12c8",
      "metadata": {},
      "source": [
        "The 'RaceDpFa' is a categorical variable. In order to run the regression, we have to convert the variable into a dummy variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ABRPG4Wi6i0L",
      "metadata": {
        "id": "ABRPG4Wi6i0L"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>imgFile</th>\n",
              "      <th>query</th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Positive</th>\n",
              "      <th>Race_asian</th>\n",
              "      <th>Race_black</th>\n",
              "      <th>Race_indian</th>\n",
              "      <th>Race_latino hispanic</th>\n",
              "      <th>Race_middle eastern</th>\n",
              "      <th>Race_white</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>batch_02_image_001_a realistic portrait photog...</td>\n",
              "      <td>reliable person</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>batch_02_image_002_a realistic portrait photog...</td>\n",
              "      <td>reliable person</td>\n",
              "      <td>55.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>batch_02_image_003_a realistic portrait photog...</td>\n",
              "      <td>unreliable person</td>\n",
              "      <td>34.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>batch_02_image_004_a realistic portrait photog...</td>\n",
              "      <td>unreliable person</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>batch_02_image_005_a realistic portrait photog...</td>\n",
              "      <td>agreeable person</td>\n",
              "      <td>31.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>855</th>\n",
              "      <td>batch_10_image_268_a realistic portrait photog...</td>\n",
              "      <td>unreliable person</td>\n",
              "      <td>44.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>856</th>\n",
              "      <td>batch_10_image_269_a realistic portrait photog...</td>\n",
              "      <td>reliable person</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857</th>\n",
              "      <td>batch_10_image_270_a realistic portrait photog...</td>\n",
              "      <td>reliable person</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>858</th>\n",
              "      <td>batch_10_image_271_a realistic portrait photog...</td>\n",
              "      <td>unreliable person</td>\n",
              "      <td>44.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>859</th>\n",
              "      <td>batch_10_image_272_a realistic portrait photog...</td>\n",
              "      <td>unreliable person</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>839 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               imgFile              query  \\\n",
              "0    batch_02_image_001_a realistic portrait photog...    reliable person   \n",
              "1    batch_02_image_002_a realistic portrait photog...    reliable person   \n",
              "2    batch_02_image_003_a realistic portrait photog...  unreliable person   \n",
              "3    batch_02_image_004_a realistic portrait photog...  unreliable person   \n",
              "4    batch_02_image_005_a realistic portrait photog...   agreeable person   \n",
              "..                                                 ...                ...   \n",
              "855  batch_10_image_268_a realistic portrait photog...  unreliable person   \n",
              "856  batch_10_image_269_a realistic portrait photog...    reliable person   \n",
              "857  batch_10_image_270_a realistic portrait photog...    reliable person   \n",
              "858  batch_10_image_271_a realistic portrait photog...  unreliable person   \n",
              "859  batch_10_image_272_a realistic portrait photog...  unreliable person   \n",
              "\n",
              "      Age Gender  Positive  Race_asian  Race_black  Race_indian  \\\n",
              "0    24.0      1       1.0           0           0            1   \n",
              "1    55.0      1       1.0           0           0            0   \n",
              "2    34.0      1       0.0           0           0            0   \n",
              "3    27.0      1       0.0           0           0            1   \n",
              "4    31.0      1       1.0           0           0            1   \n",
              "..    ...    ...       ...         ...         ...          ...   \n",
              "855  44.0      1       0.0           0           0            0   \n",
              "856  29.0      1       1.0           1           0            0   \n",
              "857  24.0      1       1.0           0           0            1   \n",
              "858  44.0      1       0.0           0           0            0   \n",
              "859  18.0      1       0.0           1           0            0   \n",
              "\n",
              "     Race_latino hispanic  Race_middle eastern  Race_white  \n",
              "0                       0                    0           0  \n",
              "1                       0                    0           1  \n",
              "2                       0                    0           1  \n",
              "3                       0                    0           0  \n",
              "4                       0                    0           0  \n",
              "..                    ...                  ...         ...  \n",
              "855                     0                    0           1  \n",
              "856                     0                    0           0  \n",
              "857                     0                    0           0  \n",
              "858                     0                    0           1  \n",
              "859                     0                    0           0  \n",
              "\n",
              "[839 rows x 11 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# One-hot encoding for regression\n",
        "df_final = pd.get_dummies(df_final, columns=['RaceDpFa'], prefix='Race')\n",
        "df_final"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "fa2926da",
      "metadata": {},
      "source": [
        "We ran the regression to on the 'Positive' variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b_b7Y4Qr6lnY",
      "metadata": {
        "id": "b_b7Y4Qr6lnY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coefficients for Age is -0.010796537143456738\n",
            "Coefficients for Gender is -0.06418555517294222\n",
            "Coefficients for Race_asian is -1.1070553398042742\n",
            "Coefficients for Race_black is 0.25235529625050895\n",
            "Coefficients for Race_indian is 0.8250675637151866\n",
            "Coefficients for Race_latino hispanic is 0.45720306516776654\n",
            "Coefficients for Race_middle eastern is 0.03565184906085017\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "X = df_final[['Age', 'Gender', 'Race_asian', 'Race_black', 'Race_indian', 'Race_latino hispanic', 'Race_middle eastern']]\n",
        "y = df_final['Positive']\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "coeff = model.coef_\n",
        "intercept = model.intercept_\n",
        "\n",
        "print(f'Coefficients for Age is {coeff[0][0]}')\n",
        "print(f'Coefficients for Gender is {coeff[0][1]}')\n",
        "print(f'Coefficients for Race_asian is {coeff[0][2]}')\n",
        "print(f'Coefficients for Race_black is {coeff[0][3]}')\n",
        "print(f'Coefficients for Race_indian is {coeff[0][4]}')\n",
        "print(f'Coefficients for Race_latino hispanic is {coeff[0][5]}')\n",
        "print(f'Coefficients for Race_middle eastern is {coeff[0][6]}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d2360b4d",
      "metadata": {},
      "source": [
        "For each 1 year increase in age, the log-odds of the outcome being positive decrease by about -0.011. When the Gender variable is 1 (male), the outcome will decrease by about -0.064. When we look at the race variables, we were able to find wide range of coefficients by gender. The Race_asian variable had a coefficient -1.107, Race_black variable had a coefficient 0.252, Race_indian had a coefficient 0.825, Race_latino hispanic had a cofficient 0.457, and Race_middle easter varialbe had a coefficient 0.0357. Positive images are more associated with Indians, Hispanics, and Middle Eastern. However, the coefficients of Age and Gender variables were close to 0. Therefore the effect was not huge on the outcome. Overall, the number of female images produced were 14. There is not enoguh female data to make accurate asumptions about female outputs. \n",
        "\n",
        "As the coefficients indicate, younger people are associated with more positive impressions. Females are more likely to be related with negative words. Those two variables are biased in but not by a lot as the coefficients are not very large. However, for races, we see very large coefficients for Indians and Middle Eastern people, indicating that people from those races are more likely to be reflecting positive attributes. This is surprising since we were expecting the algorithms would be more bias towards white people. Our analysis, on the other hand, showed the opposite results. The image generating AI favors Indians and Middle eastern people. The bias still exists, just not the way we were expecting it to be. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "decf5bbc",
      "metadata": {},
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1Cm5UkXDaOHWuwlDpEmu916H9ywgTZI5-\" width=\"500\"/>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "350cac20",
      "metadata": {},
      "source": [
        "Above is a diagram of the general architecture of our project which will help visualize the whole process. As users, to start with, we use Amazon SageMaker, written in Pyhton, to interact with APIs in this project. After giving the algorithm certain descriptions in the form of two lists of words with the same length, one is full of positive words and the other negative, we feed those words into OpenAI's DALL-E 2 API to generate many images and store those inot an Amazon S3 bucket for reproducibility. From the S3 bucket, we feed the photos into Amazon Rekognition API to generate information recognized from those photos. However, Amazon Rekognition does not provide racial information, which is crucial in our analysis. So, we will use another image recognition API called Deepface from Meta. After realizing that AWS is not compatibl with the APIs of Deepface, we copied all the images from Amazon S3 and stored them into a Google Drive and used Google Colab to access Deepface API to get racial data and added to our aggregated dataset. Lastly, we combine all the recognized data and use Sagemaker again got regression analysis, including race, age, gender and their corresponding impressions, either positive or negative. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b97ebdbb",
      "metadata": {},
      "source": [
        "Note that all the codes are written in Amazon SageMaker except for the parts that required google colab usage. We create two lists of words for describing people. Then we feed those words into DallE to generate vast amount of images and save them into an Amazon S3 bucket, which ensures reproducibility for future reference. Then we feed those images to facial recognition AIs. To add variety, we chose two AIs to compare. One is deepface by facebook. The other is Amazon Rekognition Image, which we learned during our classes. With the output for variables from those two AIs, we can proceed to data analysis stage. \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "availableInstances": [
      {
        "_defaultOrder": 0,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 4,
        "name": "ml.t3.medium",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 1,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 8,
        "name": "ml.t3.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 2,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 16,
        "name": "ml.t3.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 3,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 32,
        "name": "ml.t3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 4,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 8,
        "name": "ml.m5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 5,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 16,
        "name": "ml.m5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 6,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 32,
        "name": "ml.m5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 7,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 64,
        "name": "ml.m5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 8,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 128,
        "name": "ml.m5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 9,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 192,
        "name": "ml.m5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 10,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 256,
        "name": "ml.m5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 11,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 384,
        "name": "ml.m5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 12,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 8,
        "name": "ml.m5d.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 13,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 16,
        "name": "ml.m5d.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 14,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 32,
        "name": "ml.m5d.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 15,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 64,
        "name": "ml.m5d.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 16,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 128,
        "name": "ml.m5d.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 17,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 192,
        "name": "ml.m5d.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 18,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 256,
        "name": "ml.m5d.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 19,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 384,
        "name": "ml.m5d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 20,
        "_isFastLaunch": true,
        "category": "Compute optimized",
        "gpuNum": 0,
        "memoryGiB": 4,
        "name": "ml.c5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 21,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "memoryGiB": 8,
        "name": "ml.c5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 22,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "memoryGiB": 16,
        "name": "ml.c5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 23,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "memoryGiB": 32,
        "name": "ml.c5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 24,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "memoryGiB": 72,
        "name": "ml.c5.9xlarge",
        "vcpuNum": 36
      },
      {
        "_defaultOrder": 25,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "memoryGiB": 96,
        "name": "ml.c5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 26,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "memoryGiB": 144,
        "name": "ml.c5.18xlarge",
        "vcpuNum": 72
      },
      {
        "_defaultOrder": 27,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "memoryGiB": 192,
        "name": "ml.c5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 28,
        "_isFastLaunch": true,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "memoryGiB": 16,
        "name": "ml.g4dn.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 29,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "memoryGiB": 32,
        "name": "ml.g4dn.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 30,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "memoryGiB": 64,
        "name": "ml.g4dn.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 31,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "memoryGiB": 128,
        "name": "ml.g4dn.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 32,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "memoryGiB": 192,
        "name": "ml.g4dn.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 33,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "memoryGiB": 256,
        "name": "ml.g4dn.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 34,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "memoryGiB": 61,
        "name": "ml.p3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 35,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "memoryGiB": 244,
        "name": "ml.p3.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 36,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "memoryGiB": 488,
        "name": "ml.p3.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 37,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "memoryGiB": 768,
        "name": "ml.p3dn.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 38,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "memoryGiB": 16,
        "name": "ml.r5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 39,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "memoryGiB": 32,
        "name": "ml.r5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 40,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "memoryGiB": 64,
        "name": "ml.r5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 41,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "memoryGiB": 128,
        "name": "ml.r5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 42,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "memoryGiB": 256,
        "name": "ml.r5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 43,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "memoryGiB": 384,
        "name": "ml.r5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 44,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "memoryGiB": 512,
        "name": "ml.r5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 45,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "memoryGiB": 768,
        "name": "ml.r5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 46,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "memoryGiB": 16,
        "name": "ml.g5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 47,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "memoryGiB": 32,
        "name": "ml.g5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 48,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "memoryGiB": 64,
        "name": "ml.g5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 49,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "memoryGiB": 128,
        "name": "ml.g5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 50,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "memoryGiB": 256,
        "name": "ml.g5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 51,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "memoryGiB": 192,
        "name": "ml.g5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 52,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "memoryGiB": 384,
        "name": "ml.g5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 53,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "memoryGiB": 768,
        "name": "ml.g5.48xlarge",
        "vcpuNum": 192
      }
    ],
    "colab": {
      "provenance": []
    },
    "instance_type": "ml.t3.medium",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
